{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLCA NN Class imported\n",
      "MLCA NN_MIP Class imported\n"
     ]
    }
   ],
   "source": [
    "from docplex.mp.model import Model\n",
    "import numpy as np\n",
    "from source_torch.mlca.mlca_nn import MLCA_NN\n",
    "from source_torch.mlca.mlca_nn_mip import MLCA_NNMIP\n",
    "import pandas as pd\n",
    "import torch\n",
    "import docplex.mp.conflict_refiner as cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_model_weights(model): # torch\n",
    "    nnmodel = model.model\n",
    "    weights = []\n",
    "    for params in nnmodel.parameters():\n",
    "        weights.append(params.detach().cpu().numpy().T)        \n",
    "    return weights\n",
    "\n",
    "def _get_model_layer_shapes(model, layer_type=None):\n",
    "    ''' return layer output shapes instead, \n",
    "        if 'input' is given as desired layer type, insert input dim at the beginning.\n",
    "        assumes torch model '''\n",
    "    # nnmodel = self.Models[key]\n",
    "    nnmodel = model.model\n",
    "    Layer_shapes = []\n",
    "    for i, (name, param) in enumerate(nnmodel.named_parameters()):\n",
    "        if (i==0) and ('input' in layer_type): \n",
    "            Layer_shapes.append(param.shape[1])\n",
    "        if any([x in name for x in layer_type]) and ('bias' in name):\n",
    "            Layer_shapes.append(param.shape[0])\n",
    "    return Layer_shapes\n",
    "\n",
    "def _clean_weights(Wb):\n",
    "    for v in range(0, len(Wb)-2, 2):\n",
    "        Wb[v][abs(Wb[v]) <= 1e-8] = 0\n",
    "        Wb[v+1][abs(Wb[v+1]) <= 1e-8] = 0\n",
    "        zero_rows = np.where(np.logical_and((Wb[v] == 0).all(axis=0), Wb[v+1] == 0))[0]\n",
    "        if len(zero_rows) > 0:\n",
    "            #logging.debug('Clean Weights (rows) %s', zero_rows)\n",
    "            Wb[v] = np.delete(Wb[v], zero_rows, axis=1)\n",
    "            Wb[v+1] = np.delete(Wb[v+1], zero_rows)\n",
    "            Wb[v+2] = np.delete(Wb[v+2], zero_rows, axis=0)\n",
    "    return(Wb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it stops here\n",
      "JobSolveStatus.OPTIMAL_SOLUTION\n",
      "[0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0]\n",
      "12.5\n",
      "it stops here\n",
      "JobSolveStatus.OPTIMAL_SOLUTION\n",
      "[0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0]\n",
      "2972.0\n",
      "it stops here\n",
      "JobSolveStatus.OPTIMAL_SOLUTION\n",
      "[0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0]\n",
      "11.5\n",
      "it stops here\n",
      "JobSolveStatus.OPTIMAL_SOLUTION\n",
      "[0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0]\n",
      "12.5\n",
      "it stops here\n",
      "JobSolveStatus.OPTIMAL_SOLUTION\n",
      "[0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0]\n",
      "12.5\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "bundles = np.random.randint(2, size=(5, 10)).tolist()\n",
    "values = np.random.randint(100, size=(5, 1)).flatten().tolist()\n",
    "\n",
    "model = MLCA_NN(X_train = np.array(bundles), Y_train=np.array(values))\n",
    "model.initialize_model(model_parameters={'learning_rate': 0.001, 'architecture': [10, 10, 10], 'dropout': False, 'dropout_prob': 0.2, 'regularization_type': 'l2', 'regularization': 0.01}, device= device)\n",
    "\n",
    "#big integer\n",
    "C = 6000\n",
    "L = 6000\n",
    "\n",
    "count = 1\n",
    "while count > 0:\n",
    "    count -= 1\n",
    "\n",
    "    model.X_train = np.array(bundles)\n",
    "    model.Y_train = np.array(values)\n",
    "    model.fit(epochs=100, batch_size=32)\n",
    "\n",
    "    weights = _get_model_weights(model)\n",
    "    layers = _get_model_layer_shapes(model, layer_type=['dense', 'input'])\n",
    "    Wb = _clean_weights(weights)\n",
    "    W = Wb[0]\n",
    "    bias = Wb[1]\n",
    "\n",
    "    n = len(bundles)\n",
    "    num_items = len(bundles[0])\n",
    "\n",
    "    vectors = []\n",
    "    distances = []\n",
    "\n",
    "    for i in range(n):\n",
    "        m  = Model(name='galo_nn')\n",
    "        z = {}\n",
    "        y = {}\n",
    "        q = {}\n",
    "        r = m.continuous_var(name='r')\n",
    "        x = m.binary_var_list(range(num_items), name='x')\n",
    "        b = m.binary_var_list(range(n), name='b')\n",
    "        l_layer = len(layers)-1\n",
    "        for layer, neurons in enumerate(layers):\n",
    "            for neuron in range(neurons):\n",
    "                z[layer, neuron] = m.continuous_var(name='z_{}_{}'.format(str(layer), str(neuron)))\n",
    "                y[layer, neuron] = m.binary_var(name='y_{}_{}'.format(str(layer), str(neuron)))\n",
    "                q[layer, neuron] = m.continuous_var(name='q_{}_{}'.format(str(layer), str(neuron)))\n",
    "        \n",
    "        for neuron in range(num_items): \n",
    "            m.add_constraint(z[0, neuron] == x[neuron])\n",
    "\n",
    "        m.add_constraint(values[i] - z[l_layer, 0] <= r)\n",
    "        m.add_constraint(z[l_layer, 0] - values[i] <= r)\n",
    "        \n",
    "        for j in range(n):\n",
    "            m.add_constraint(x[j] <= 1)\n",
    "            m.add_constraint(b[j] <= 1)\n",
    "            m.add_constraint(values[j] - z[l_layer, 0] + C * b[j] >= r)\n",
    "            m.add_constraint(z[l_layer, 0] - values[j] + C * (1- b[j]) >= r)\n",
    "\n",
    "        for layer, neurons in enumerate(layers):\n",
    "            if layer == 0: continue\n",
    "            for neuron in range(neurons):\n",
    "                if z[layer, neuron] is z[l_layer, 0]:\n",
    "                    print('it stops here')\n",
    "                    break\n",
    "                m.add_constraint(z[layer, neuron] - q[layer, neuron] == W[layer-1][neuron] * z[layer-1, neuron] + bias[layer-1])\n",
    "                m.add_constraint(0 <= z[layer, neuron])\n",
    "                m.add_constraint(z[layer, neuron] <= y[layer, neuron] * L)                \n",
    "                m.add_constraint(0 <= q[layer, neuron])\n",
    "                m.add_constraint(q[layer, neuron] <=(1 - y[layer, neuron]) * L)\n",
    "\n",
    "        m.maximize(r)\n",
    "        m.solve()\n",
    "        res = m.get_solve_status()\n",
    "        print(res)\n",
    "        # if res.name == 'INFEASIBLE_SOLUTION':  # or also 'INFEASIBLE_OR_UNBOUNDED_SOLUTION'\n",
    "        #     cref = cr.ConflictRefiner()\n",
    "        #     print('show some of the constraints that can be removed to arrive at a minimal conflict')\n",
    "        #     confl = cref.refine_conflict(m, display=True)  # display flag is to show the conflicts\n",
    "        #     #print('Initial y')\n",
    "        #     #print(values[bundle])\n",
    "        #     #print('Intercept')\n",
    "        #     #print(intercept)\n",
    "        #     cref.display_conflicts(confl)\n",
    "        c_bundle = [x[k].solution_value for k in range(num_items)]\n",
    "        vectors.append(c_bundle)\n",
    "        distances.append(r.solution_value)\n",
    "        print(c_bundle)\n",
    "        print(r.solution_value)\n",
    "    # print('Here is all r values and bundles')\n",
    "    # print(distances)\n",
    "    # print(vectors)\n",
    "    # print('Here is the biggest distance')\n",
    "    # print(np.argmax(distances))\n",
    "    # print('Here is the bundle to add')\n",
    "    #print(vectors[np.argmax(distances)])\n",
    "    bundles.append(vectors[np.argmax(distances)])\n",
    "    values.append(np.random.randint(1,100))\n",
    "# print(bundles)\n",
    "# print(values)\n",
    "#free cuda cache\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ica_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
