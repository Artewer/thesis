{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLCA NN Class imported\n",
      "MLCA NN_MIP Class imported\n"
     ]
    }
   ],
   "source": [
    "from docplex.mp.model import Model\n",
    "import numpy as np\n",
    "from source_torch.mlca.mlca_nn import MLCA_NN\n",
    "from source_torch.mlca.mlca_nn_mip import MLCA_NNMIP\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLCA_GALO_MIP:\n",
    "    def __init__(self, value_model, bidder_id, presampled_algorithm='unif', presampled_n=10, L = 6000):\n",
    "        self.bidder_id = bidder_id\n",
    "        self.Mip = Model(name='MLCA_GALO_MIP')\n",
    "        self.presampled_algorithm = presampled_algorithm\n",
    "        self.presampled_n = presampled_n\n",
    "        #if self.presampled_algorithm == 'gali':\n",
    "        #    D_presampled = util.gali_bids_init(value_model=value_model, bidder_id=bidder_id, n=presampled_n)\n",
    "        #else:\n",
    "        #    D_presampled = util.unif_random_bids(value_model=value_model, bidder_id=bidder_id, n=presampled_n)\n",
    "        #self.values = D_presampled[:, -1].tolist()\n",
    "        \n",
    "        #self.bundles = D_presampled[:, :-1].tolist()\n",
    "        \n",
    "        self.values = np.random.randint(1, 100, size=(self.presampled_n, 1)).tolist()\n",
    "        self.bundles = np.random.randint(0, 2, size=(self.presampled_n, 10)).tolist()\n",
    "        self.M = len(self.bundles[0])#number of items\n",
    "        self.bidder_model = self.train()\n",
    "        self.bidder_name = 'Bidder 0'\n",
    "        #test = self._get_model_layer_shapes(self.bidder_model, layer_type=['dense', 'input'])\n",
    "        self.L = L  # global big-M variable: see paper\n",
    "        print(self._get_model_layer_shapes(self.bidder_model, layer_type=['dense', 'input']))\n",
    "        #print(self._get_model_layer_shapes(self.bidder_model, layer_type=['dense', 'input']))\n",
    "        self.upper_bounds_z = {self.bidder_name: np.array([self.L]*self._get_model_layer_shapes(self.bidder_model, layer_type=['dense', 'input'])).reshape(-1, 1)}\n",
    "        self.upper_bounds_s = {self.bidder_name: np.array([self.L]*self._get_model_layer_shapes(self.bidder_model, layer_type=['dense', 'input'])).reshape(-1, 1)}\n",
    "        self.z = {}  # MIP variable: see paper\n",
    "        self.s = {}  # MIP variable: see paper\n",
    "        self.y = {}  # MIP variable: see paper\n",
    "        self.x_star = np.ones((self.N, self.M))*(-1)  # optimal allocation (-1=not yet solved)\n",
    "        self.soltime = None  # timing\n",
    "        \n",
    "                \n",
    "\n",
    "    def train(self):\n",
    "        model = MLCA_NN(X_train = np.array(self.bundles), Y_train=np.array(self.values))\n",
    "        model.initialize_model(model_parameters={'learning_rate': 0.001, 'architecture': [10, 10, 10], 'dropout': False, 'dropout_prob': 0.2, 'device': 'cpu', 'regularization_type': 'l2', 'regularization': 0.01})\n",
    "        model.fit(epochs=10, batch_size=32)\n",
    "        return model\n",
    "    \n",
    "    def _get_model_weights(model): # torch\n",
    "        nnmodel = model.model\n",
    "        weights = []\n",
    "        for params in nnmodel.parameters():\n",
    "            weights.append(params.detach().cpu().numpy().T)        \n",
    "        return weights\n",
    "\n",
    "    def _get_model_layer_shapes(model, layer_type=None):\n",
    "        ''' return layer output shapes instead, \n",
    "            if 'input' is given as desired layer type, insert input dim at the beginning.\n",
    "            assumes torch model '''\n",
    "        # nnmodel = self.Models[key]\n",
    "        nnmodel = model.model\n",
    "        Layer_shapes = []\n",
    "        for i, (name, param) in enumerate(nnmodel.named_parameters()):\n",
    "            if (i==0) and ('input' in layer_type): \n",
    "                Layer_shapes.append(param.shape[1])\n",
    "            if any([x in name for x in layer_type]) and ('bias' in name):\n",
    "                Layer_shapes.append(param.shape[0])\n",
    "        return Layer_shapes\n",
    "\n",
    "    def _clean_weights(Wb):\n",
    "        for v in range(0, len(Wb)-2, 2):\n",
    "            Wb[v][abs(Wb[v]) <= 1e-8] = 0\n",
    "            Wb[v+1][abs(Wb[v+1]) <= 1e-8] = 0\n",
    "            zero_rows = np.where(np.logical_and((Wb[v] == 0).all(axis=0), Wb[v+1] == 0))[0]\n",
    "            if len(zero_rows) > 0:\n",
    "                logging.debug('Clean Weights (rows) %s', zero_rows)\n",
    "                Wb[v] = np.delete(Wb[v], zero_rows, axis=1)\n",
    "                Wb[v+1] = np.delete(Wb[v+1], zero_rows)\n",
    "                Wb[v+2] = np.delete(Wb[v+2], zero_rows, axis=0)\n",
    "        return(Wb)\n",
    "    \n",
    "\n",
    "    def optimization_step_nn(self):\n",
    "        attempts = self.MIP_parameters['attempts_DNN_WDP']\n",
    "        for attempt in range(1, attempts+1):\n",
    "            logging.debug('Initialize MIP for GALO(NN)')\n",
    "            #X = MLCA_NNMIP(DNNs, L=self.MIP_parameters['bigM'])\n",
    "            if not self.MIP_parameters['mip_bounds_tightening']:\n",
    "                print('MIP bounds not tightening is not implemented yet')\n",
    "            elif self.MIP_parameters['mip_bounds_tightening'] == 'IA':\n",
    "                #This is what usually happens\n",
    "                self.tighten_bounds_IA(upper_bound_input=[1]*self.M)\n",
    "                #X.print_upper_bounds(only_zeros=True)\n",
    "                X.initialize_mip(verbose=False, bidder_specific_constraints=bidder_specific_constraints)\n",
    "            elif self.MIP_parameters['mip_bounds_tightening'] == 'LP':\n",
    "                print('MIP bounds tightening == LP is not implemented yet')\n",
    "                #X.tighten_bounds_IA(upper_bound_input=[1]*self.M)\n",
    "                #X.tighten_bounds_LP(upper_bound_input=[1]*self.M)\n",
    "                #X.print_upper_bounds(only_zeros=True)\n",
    "                #X.initialize_mip(verbose=False, bidder_specific_constraints=bidder_specific_constraints)\n",
    "            try:\n",
    "                logging.info('Solving MIP')\n",
    "                logging.info('Attempt no: %s', attempt)\n",
    "                if self.MIP_parameters['warm_start'] and self.warm_start_sol[economy_key] is not None:\n",
    "                    logging.debug('Using warm start')\n",
    "                    self.warm_start_sol[economy_key] = X.solve_mip(log_output=False, time_limit=self.MIP_parameters['time_limit'],\n",
    "                                                                   mip_relative_gap=self.MIP_parameters['relative_gap'], integrality_tol=self.MIP_parameters['integrality_tol'],\n",
    "                                                                   mip_start=docplex.mp.solution.SolveSolution(X.Mip, self.warm_start_sol[economy_key].as_dict()))\n",
    "                else:\n",
    "                    self.warm_start_sol[economy_key] = X.solve_mip(log_output=False, time_limit=self.MIP_parameters['time_limit'],\n",
    "                                                                   mip_relative_gap=self.MIP_parameters['relative_gap'], integrality_tol=self.MIP_parameters['integrality_tol'])\n",
    "\n",
    "                if bidder_specific_constraints is None:\n",
    "                    logging.debug('SET ARGMAX ALLOCATION FOR ALL BIDDERS')\n",
    "                    b = 0\n",
    "                    for bidder in self.argmax_allocation[economy_key].keys():\n",
    "                        self.argmax_allocation[economy_key][bidder][0] = X.x_star[b, :]\n",
    "                        b = b + 1\n",
    "                else:\n",
    "                    logging.debug('SET ARGMAX ALLOCATION ONLY BIDDER SPECIFIC for {}'.format(list(bidder_specific_constraints.keys())[0]))\n",
    "                    for bidder in bidder_specific_constraints.keys():\n",
    "                        b = X.get_bidder_key_position(bidder_key=bidder)  # transform bidder_key into bidder position in MIP\n",
    "                        self.argmax_allocation[economy_key][bidder][1] = X.x_star[b, :]  # now on position 1!\n",
    "\n",
    "                for key,value in self.argmax_allocation[economy_key].items():\n",
    "                    logging.debug(key + ':  %s | %s', value[0], value[1])\n",
    "\n",
    "                self.elapsed_time_mip[economy_key].append(X.soltime)\n",
    "                break\n",
    "            except Exception:\n",
    "                logging.warning('-----------------------------------------------')\n",
    "                logging.warning('NOT SUCCESSFULLY SOLVED in attempt: %s \\n', attempt)\n",
    "                logging.warning(X.Mip.solve_details)\n",
    "                if attempt == attempts:\n",
    "                    X.Mip.export_as_lp(basename='UnsolvedMip_iter{}_{}'.format(self.mlca_iteration, economy_key),path=os.getcwd(), hide_user_names=False)\n",
    "                    sys.exit('STOP, not solved succesfully in {} attempts\\n'.format(attempt))\n",
    "                \n",
    "                # clear_session()\n",
    "                logging.debug('REFITTING:')\n",
    "                self.estimation_step(economy_key=economy_key)\n",
    "            DNNs = OrderedDict(list((key, self.NN_models[economy_key][key].model) for key in list(self.NN_models[economy_key].keys())))\n",
    "        del X\n",
    "        del DNNs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def tighten_bounds_IA(self, upper_bound_input, bidder_model, verbose=False):\n",
    "        bidder = self.bidder_name\n",
    "        Wb_total = util._clean_weights(util._get_model_weights(bidder_model))\n",
    "        k = 0\n",
    "        for j in range(len(util._get_model_layer_shapes(bidder_model, layer_type=['dense', 'input']))):  # loop over layers including input layer\n",
    "                if j == 0:\n",
    "                    self.upper_bounds_z[bidder][j] = np.array(upper_bound_input).reshape(-1, 1)\n",
    "                    self.upper_bounds_s[bidder][j] = np.array(upper_bound_input).reshape(-1, 1)\n",
    "                else:\n",
    "                    W_plus = np.maximum(Wb_total[k].transpose(), 0)\n",
    "                    W_minus = np.minimum(Wb_total[k].transpose(), 0)\n",
    "                    self.upper_bounds_z[bidder][j] = np.ceil(np.maximum(W_plus @ self.upper_bounds_z[bidder][j-1] + Wb_total[k+1].reshape(-1, 1), 0)).astype(int)   # upper bound for z\n",
    "                    self.upper_bounds_s[bidder][j] = np.ceil(np.maximum(-(W_minus @ self.upper_bounds_z[bidder][j-1] + Wb_total[k+1].reshape(-1, 1)), 0)).astype(int)  # upper bound  for s\n",
    "                    k = k+2\n",
    "        if verbose is True:\n",
    "            logging.debug('Upper Bounds z:')\n",
    "            for k, v in pd.DataFrame({k: pd.Series(l) for k, l in self.upper_bounds_z.items()}).fillna('-').items():\n",
    "                logging.debug(v)\n",
    "            logging.debug('\\nUpper Bounds s:')\n",
    "            for k, v in pd.DataFrame({k: pd.Series(l) for k, l in self.upper_bounds_s.items()}).fillna('-').items():\n",
    "                logging.debug(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_model_weights(model): # torch\n",
    "    nnmodel = model.model\n",
    "    weights = []\n",
    "    for params in nnmodel.parameters():\n",
    "        weights.append(params.detach().cpu().numpy().T)        \n",
    "    return weights\n",
    "\n",
    "def _get_model_layer_shapes(model, layer_type=None):\n",
    "    ''' return layer output shapes instead, \n",
    "        if 'input' is given as desired layer type, insert input dim at the beginning.\n",
    "        assumes torch model '''\n",
    "    # nnmodel = self.Models[key]\n",
    "    nnmodel = model.model\n",
    "    Layer_shapes = []\n",
    "    for i, (name, param) in enumerate(nnmodel.named_parameters()):\n",
    "        if (i==0) and ('input' in layer_type): \n",
    "            Layer_shapes.append(param.shape[1])\n",
    "        if any([x in name for x in layer_type]) and ('bias' in name):\n",
    "            Layer_shapes.append(param.shape[0])\n",
    "    return Layer_shapes\n",
    "\n",
    "def _clean_weights(Wb):\n",
    "    for v in range(0, len(Wb)-2, 2):\n",
    "        Wb[v][abs(Wb[v]) <= 1e-8] = 0\n",
    "        Wb[v+1][abs(Wb[v+1]) <= 1e-8] = 0\n",
    "        zero_rows = np.where(np.logical_and((Wb[v] == 0).all(axis=0), Wb[v+1] == 0))[0]\n",
    "        if len(zero_rows) > 0:\n",
    "            logging.debug('Clean Weights (rows) %s', zero_rows)\n",
    "            Wb[v] = np.delete(Wb[v], zero_rows, axis=1)\n",
    "            Wb[v+1] = np.delete(Wb[v+1], zero_rows)\n",
    "            Wb[v+2] = np.delete(Wb[v+2], zero_rows, axis=0)\n",
    "    return(Wb)\n",
    "\n",
    "np.random.seed(0)\n",
    "bundles = np.random.randint(2, size=(5, 10))\n",
    "values = np.random.randint(100, size=(5, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 10, 10, 10, 1]\n",
      "[ 0.          0.00990307  0.01008305  0.0100156  -0.00928468 -0.00950962\n",
      "  0.00587529 -0.00937601 -0.00975979  0.01002414]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "M = 10\n",
    "#big integer\n",
    "C = 6000\n",
    "L = 6000\n",
    "#while count < 10:\n",
    "model = MLCA_NN(X_train = bundles, Y_train=values)\n",
    "model.initialize_model(model_parameters={'learning_rate': 0.001, 'architecture': [10, 10, 10], 'dropout': False, 'dropout_prob': 0.2, 'regularization_type': 'l2', 'regularization': 0.01}, device= 'cpu')\n",
    "model.fit(epochs=10, batch_size=32)\n",
    "weights = _get_model_weights(model)\n",
    "layers = _get_model_layer_shapes(model, layer_type=['dense', 'input'])\n",
    "Wb = _clean_weights(weights)\n",
    "print(layers)\n",
    "#print(weights[5])    \n",
    "print(Wb[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(values)):\n",
    "        m  = Model(name='galo_nn')\n",
    "        #create z^k variables\n",
    "        z = {}\n",
    "        y = {}\n",
    "        q = {}\n",
    "        #print(z)\n",
    "        r = m.continuous_var(name='r')\n",
    "        #x = m.binary_var_list(range(M), name='x')\n",
    "        b = m.binary_var_list(range(len(values)), name='b')\n",
    "        \n",
    "        constraints = []\n",
    "        constraints.append(values[i] - z[-1][0] <= r)\n",
    "        constraints.append(z[-1][0] - values[i] <= r)\n",
    "        \n",
    "        for i in range(len(values)):\n",
    "            constraints.append(values[i] - z[-1][0] + C * b[i] <= r)\n",
    "            constraints.append(z[-1][0] - values[i] + C * (1- b[i]) <= r)\n",
    "        \n",
    "\n",
    "    count += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ica_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
